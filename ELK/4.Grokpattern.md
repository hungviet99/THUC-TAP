# Sử dụng grok phân tích log 

## 1. Sử dụng grok phân tích log ssh 

- Thêm phần sau vào trường `filebeat.inputs` trong cấu hình filebeat:

```
vi /etc/filebeat/filebeat.yml
```
và thêm các trường sau : 

```
- type: log
  paths:
    - /var/log/secure
  tags: ssh
```

- Khởi động lại filebeat:

```
systemctl restart filebeat
```

Tại elk server : 

- Thêm custom pattern cho SSH

Tạo file pattern `/usr/share/logstash/patterns/ssh`, và thêm vào nội dung sau:

```
SSHFAILED Failed %{WORD:auth_method} for %{USER:username} from %{IP:src_ip} port %{INT:src_port} ssh2
SSHACC Accepted %{WORD:auth_method} for %{USER:username} from %{IP:src_ip} port %{INT:src_port} ssh2
SSHFU Failed %{WORD:auth_method} for invalid user %{USER:username} from %{IP:src_ip} port %{INT:src_port} ssh2
```

- Tạo file cấu hình input filebeat tại ELK server

Tạo file `/etc/logstash/conf.d/input.conf` và thêm nội dung sau:

```
input {
  beats {
    port => 5044
    ssl => false
  }
}
```

- Tạo file cấu hình logstash cho SSH

Tạo file `/etc/logstash/conf.d/ssh.conf` và thêm vào nội dung sau:

```
filter {
  if "ssh" in [tags] {
    grok {
      patterns_dir => "/usr/share/logstash/patterns"
      match => { "message" => "%{SSHFAILED}" }
      match => { "message" => "%{SSHACC}" }
      match => { "message" => "%{SSHFU}" }
      match => { "message" => "%{SYSLOGTIMESTAMP:time} %{HOSTNAME:hostname} %{SYSLOGPROG}: %{GREEDYDATA:message}" }
      overwrite => "message"
      #remove_tag => ["_grokparsefailure"]
    }
  }
}
output {
  if "ssh" in [tags] {
    elasticsearch {
      hosts => ["localhost:9200"]
      sniffing => false
      index => "ssh-%{+YYYY.MM.dd}"
    }
  }
}
```

- Khởi động lại logstash:

```
systemctl restart logstash
```

## 2. Sử dụng grok phân tích log http

Phía client : 

- Cấu hình filebeat gửi log http:

Thêm nội dung sau vào trường `filebeat.inputs`:

```
- type: log
  paths:
    - /var/log/httpd/access_log
  tags: http_access
- type: log
  paths:
    - /var/log/httpd/error_log
  tags: http_error
```

- Khởi động lại filebeat

```
systemctl restart filebeat
```

Tại elk server

- Cấu hình logstash cho HTTP

Tạo file cấu hình `/etc/logstash/conf.d/http.conf` và thêm vào nội dung sau:

```
filter {
  if "http_access" in [tags] {
    grok {
          match => { "message" => "%{COMBINEDAPACHELOG}" }
        }
  }
  if "http_error" in [tags] {
    grok {
      match => { "message" => "{%HTTPD_ERRORLOG}" }
    }
  }
}

output {
  if "http_access" in [tags] {
    elasticsearch {
      hosts => ["localhost:9200"]
      index => "http_access-%{+YYYY.MM.dd}"
    }
  }
  if "http_error" in [tags] {
    elasticsearch {
      hosts => ["localhost:9200"]
      index => "http_error-%{+YYYY.MM.dd}"
    }
  }
}
```

- Khởi động lại logstash

```
systemctl restart logstash
```

## 3. Sử dụng grok phân tích cmdlog 

Phía client :

Thực thi lệnh sau để cài cmdlog 

```
curl -Lso- https://raw.githubusercontent.com/nhanhoadocs/ghichep-cmdlog/master/cmdlog.sh | bash
```

logout và login lại.

- Cấu hình filebeat gửi log cmdlog:

Thêm nội dung sau vào trường `filebeat.inputs`:

```
- type: log
  paths:
    - /var/log/cmdlog.log
  tags: cmdlog
```

- Khởi động lại filebeat

```
systemctl restart filebeat
```

Phía server : 

- Tạo file pattern `vi /usr/share/logstash/patterns/cmdlog` với nội dung sau:

```
CMDLOG %{SYSLOGTIMESTAMP:time} %{HOSTNAME:hostname} %{WORD}: %{USER:user} \[%{POSINT:uid}\]: %{GREEDYDATA:command}
```

- Tạo file `vi /etc/logstash/conf.d/cmdlog.conf` cấu hình Logstash:

```
input {
  file {
    type => "cmdlog"
    start_position => "beginning"
    path => [ "/var/log/cmdlog.log" ]
  }
}

filter {
  if [type] == "cmdlog" {
    grok {
      patterns_dir => "/usr/share/logstash/patterns"
      match => { "message" => "%{CMDLOG}" }
    }
  }
}

output {
  elasticsearch {
    index => "cmdlog"
    hosts => ["localhost:9200"]
  }
}
```

- Khởi động lại Logstash

```
systemctl restart logstash 
```

